{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b643042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import seaborn as sn\n",
    "import smogn\n",
    "import statsmodels.api as sm\n",
    "from numpy.fft import fft, ifft\n",
    "from statistics import mode, median, quantiles\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.robust.scale import iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b6bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x0,y0,x1,y1):\n",
    "    '''\n",
    "    Distance in cartesian coordinate system\n",
    "    '''\n",
    "    return math.sqrt((x0-x1)**2+(y0-y1)**2)\n",
    "\n",
    "def angular_amplitude_entropy(values, min_val=0, max_val=90, n_buckets=18):\n",
    "    '''\n",
    "    Given a series of angular amplitudes (degree), find the entropy of the series.\n",
    "    Assumptions: the values are between 0 and 90\n",
    "    '''\n",
    "    dA = (max_val - min_val) / (n_buckets - 1)\n",
    "    buckets = np.arange(min_val, max_val + 1, dA)\n",
    "    n = np.histogram(values, buckets)[0]\n",
    "    p = n / n.sum()\n",
    "    p[p == 0] = 1\n",
    "    lp = np.log(p)\n",
    "    ppe = -np.multiply(p, lp).sum() / np.log(n_buckets)\n",
    "    return ppe\n",
    "\n",
    "def period_entropy(values, min_val=0, max_val=2, n_buckets=50):\n",
    "    '''\n",
    "    Given a series of periods (s), find the entropy of the series.\n",
    "    Assumptions: the values are between 0s and 2s\n",
    "    '''\n",
    "    dA = (max_val - min_val) / (n_buckets - 1)\n",
    "    buckets = np.arange(min_val, max_val + 1, dA)\n",
    "    n = np.histogram(values, buckets)[0]\n",
    "    p = n / n.sum()\n",
    "    p[p == 0] = 1\n",
    "    lp = np.log(p)\n",
    "    ppe = -np.multiply(p, lp).sum() / np.log(n_buckets)\n",
    "    return ppe\n",
    "\n",
    "def entropy(p):\n",
    "    '''\n",
    "    p: np.array of probabilities\n",
    "    '''\n",
    "    return -(p*np.log(p)).sum()\n",
    "\n",
    "def get_length(filename):\n",
    "    '''\n",
    "    Given a video filename, find its length in seconds.\n",
    "    '''\n",
    "    out = subprocess.check_output([\"ffprobe\", \"-v\", \"quiet\", \"-show_format\", \"-print_format\", \"json\", filename])\n",
    "    ffprobe_data = json.loads(out)\n",
    "    duration_seconds = float(ffprobe_data[\"format\"][\"duration\"])\n",
    "    return duration_seconds\n",
    "\n",
    "def denoise(D, WINDOW_SIZE = 3, THRESHOLD = 3):\n",
    "    '''\n",
    "    Denoise (missing hands) a series of angular distances. \n",
    "    Look at values before and after. If majority are missing hands, most likely the task is yet to start, \n",
    "    and this is actually a missing hand. If minority are missing, do interpolation to replace the missing value.\n",
    "    Parameters:\n",
    "            WINDOW_SIZE: how many time-steps we are looking at to the left and right of \n",
    "            the current time-step when hand is not detected by mediapipe\n",
    "            \n",
    "            THRESHOLD: if number neighbor frames with undetected hands is at most the threshold, then interpolate\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    Learn a 3-degree polynomial Y that copies D or <fit and interpolate> D for missing data\n",
    "    '''\n",
    "    D = list(D)\n",
    "    Y = []\n",
    "    for i in range(0,len(D)):\n",
    "        if D[i] != -1.0:\n",
    "            Y.append(D[i])\n",
    "        else:\n",
    "            Y.append(np.nan)\n",
    "    \n",
    "    Y = pd.Series(Y)\n",
    "    Y = Y.interpolate(method=\"polynomial\", order=3)\n",
    "    \n",
    "    for i in range(0,len(Y)):\n",
    "        if Y[i]<0:\n",
    "            Y[i] = -1.0\n",
    "    \n",
    "    '''\n",
    "    Look at <WINDOW_SIZE> values left and right to the current one. \n",
    "    If missing values > <THRESHOLD>, it remains a missing value. Otherwise, interpolation value (Y) is used.\n",
    "    '''\n",
    "    \n",
    "    for i in range(0,len(D)):\n",
    "        if D[i]==-1.0:\n",
    "            if i>=WINDOW_SIZE:\n",
    "                vals_before = D[(i-WINDOW_SIZE):(i-1)]\n",
    "            else:\n",
    "                vals_before = D[0:(i-1)]\n",
    "                for j in range(0,WINDOW_SIZE-len(vals_before)):\n",
    "                    vals_before = [-1.0] + vals_before\n",
    "                    \n",
    "            if i<(len(D)-WINDOW_SIZE):\n",
    "                vals_after = D[(i+1):(i+WINDOW_SIZE)]\n",
    "            else:\n",
    "                vals_after = D[(i+1):]\n",
    "                for j in range(0,WINDOW_SIZE-len(vals_after)):\n",
    "                    vals_after = vals_after + [-1.0]\n",
    "    \n",
    "            vals = vals_before + [-1.0] + vals_after\n",
    "            if(len(np.argwhere(np.asarray(vals)==-1.0))<=THRESHOLD):\n",
    "                D[i] = Y[i]\n",
    "                if np.isnan(D[i]):\n",
    "                    D[i] = -1.0\n",
    "    \n",
    "    return np.asarray(D)\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "def custom_peaks(D, distance):\n",
    "    '''\n",
    "    Given a signal D(t), determine the peaks with the constraint: \n",
    "        peak-to-peak distance must be at least 'distance' (expressed as the number of frames)\n",
    "    Method: First, find the peaks with distance constraint. \n",
    "            Then determine the peaks from the middle part of the time series, take the maximum peak.\n",
    "            If maximum peak>30, set maximum peak to 30 (might be due to noise or projection issue)\n",
    "            Add extra constraint: any detected peak must have height at least one-third of the maximum peak\n",
    "            Find peaks again from the input time series with height and distance constraints.\n",
    "    '''\n",
    "    peaks, _ = find_peaks(D, distance=(int)(distance))\n",
    "    n_peaks = len(peaks)\n",
    "    middle_peaks = D[peaks[(int)(np.floor((n_peaks-1)/4)):(int)(np.floor(3*(n_peaks-1)/4))]]\n",
    "    high_peak = np.percentile(middle_peaks, 80)\n",
    "    height = np.floor(high_peak/2)\n",
    "    #print(\"Peak min height: %.3f\"%(height))\n",
    "    #max_height = np.minimum(np.max(middle_peaks),30)\n",
    "    #height = np.floor(max_height/3)\n",
    "    peaks, _ = find_peaks(D, distance=(int)(distance), height = (int)(height))\n",
    "    return peaks\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "def custom_bottoms(D, distance):\n",
    "    #ensure this is a numpy array\n",
    "    D = np.asarray(list(D))\n",
    "    DI = 180 - D\n",
    "    return custom_peaks(DI, distance)\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "def get_stats(series):\n",
    "    '''\n",
    "    series = [periods_denoised, periods_trimmed]\n",
    "    '''\n",
    "    stats = {}\n",
    "    stats['median'] = median(series)\n",
    "    stats['quartile_range'] = iqr(series)\n",
    "    stats['mean'] = np.mean(series)\n",
    "    stats['min'] = np.min(series)\n",
    "    stats['max'] = np.max(series)\n",
    "    stats['stdev'] = np.std(series)\n",
    "\n",
    "    return stats\n",
    "\n",
    "def linear_regression_fit(series_x, series_y):\n",
    "    fit = {}\n",
    "    series_x = np.asarray(series_x).reshape((-1, 1))\n",
    "    series_y = np.asarray(series_y)\n",
    "    model = LinearRegression()\n",
    "    model.fit(series_x, series_y)\n",
    "    fit[\"fitness_r2\"] = model.score(series_x, series_y)\n",
    "    fit[\"slope\"] = model.coef_[0]\n",
    "    return fit\n",
    "                               \n",
    "def degree_for_good_fit(series_x, series_y, fitness_threshold = 0.90):\n",
    "    d = 0\n",
    "    r2 = 0\n",
    "    while r2<fitness_threshold:\n",
    "        d +=1\n",
    "        x = np.asarray(series_x)\n",
    "        y = np.asarray(series_y)\n",
    "        z = np.polyfit(x, y, d)\n",
    "        p = np.poly1d(z)\n",
    "        r2 = r2_score(y,p(x))\n",
    "        \n",
    "        if d>=10:\n",
    "            return d\n",
    "        \n",
    "    return d\n",
    "\n",
    "# Customized on top of MediaPipe output to detect the correct hand and track key points\n",
    "class HandTrackerCustomized():\n",
    "    '''\n",
    "    Use mediapipe to track coordinates of finger joints\n",
    "    '''\n",
    "    def __init__(self, mode=False, maxHands=2, detectionCon=0.5,modelComplexity=1,trackCon=0.5):\n",
    "        '''\n",
    "        Default initialization, maxHands is set to 2 since both hands are visible in some videos\n",
    "        '''\n",
    "        self.mode = mode\n",
    "        self.maxHands = maxHands\n",
    "        self.detectionCon = detectionCon\n",
    "        self.modelComplex = modelComplexity\n",
    "        self.trackCon = trackCon\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(self.mode, self.maxHands,self.modelComplex,\n",
    "                                        self.detectionCon, self.trackCon)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "    def handsFinder(self,image,hand='left',draw=True):\n",
    "        '''\n",
    "        Finf the coordinates for a specific hand (left/right)\n",
    "        inputs:\n",
    "            image (BGR; video frame)\n",
    "            hand: left, right\n",
    "            draw: draw coordinates on the image?\n",
    "        '''\n",
    "        hand = hand.lower()\n",
    "        \n",
    "        imageRGB = cv.cvtColor(image,cv.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imageRGB)\n",
    "        landmarks = {}\n",
    "        \n",
    "        SINGLE_HANDED = False\n",
    "        '''\n",
    "        Mediapipe may detect multiple hands. \n",
    "        We need to identify the mediapipe index of the specific hand we are trying to identify.\n",
    "        '''\n",
    "        LH_INDEX = -1\n",
    "        \n",
    "        '''\n",
    "        Assuming Mediapipe is predicting the reverse hand.\n",
    "        The reversal is necessary because mediapipe expects the selfie videos as mirrored. \n",
    "        But PARK platforms does not apply mirror effect.\n",
    "        Need to consider this if any future change impacts this assumption.\n",
    "        '''\n",
    "        \n",
    "        t_label = {\"left\":\"Right\",\"right\":\"Left\"}\n",
    "        \n",
    "        if self.results.multi_handedness:\n",
    "            if len(self.results.multi_handedness)==1:\n",
    "                '''\n",
    "                Mediapipe detects a single hand. \n",
    "                Just verify that it is our desired hand (L/R), set the index to 0.\n",
    "                Else, the index remains -1, means no hand detected.\n",
    "                '''\n",
    "                SINGLE_HANDED = True\n",
    "                which_hand = self.results.multi_handedness[0].classification[0].label\n",
    "                conf_score = self.results.multi_handedness[0].classification[0].score\n",
    "                \n",
    "                if which_hand==t_label[hand] and conf_score>0.9:\n",
    "                    LH_INDEX = 0\n",
    "                \n",
    "            else:\n",
    "                '''\n",
    "                Mediapipe detects multiple hands.\n",
    "                Find out the desired hand and set the index accordingly. If only one hand, all good!\n",
    "                If none of the hands is the desired one, the index remains -1.\n",
    "                If two desired hands (most likely, multiple people in the camera), select the bigger hand.\n",
    "                If more than two desired hand, this is an exceptional case we need to re-implement. For now, return undetected hand (-1).\n",
    "                '''\n",
    "                indexes = []\n",
    "                \n",
    "                for j in range(0,len(self.results.multi_handedness)):\n",
    "                    if self.results.multi_handedness[j].classification[0].label==t_label[hand] and self.results.multi_handedness[j].classification[0].score>0.9:\n",
    "                        indexes.append(j)\n",
    "                        \n",
    "                if len(indexes)==1:\n",
    "                    LH_INDEX = indexes[0]\n",
    "                    \n",
    "                elif len(indexes)==2:\n",
    "                    #Calculate size and pick the bigger one\n",
    "                    print(\"Both hands detected as %s\\n\"%(hand))\n",
    "                    handLms0 = self.results.multi_hand_landmarks[indexes[0]]\n",
    "                    handLms1 = self.results.multi_hand_landmarks[indexes[1]]\n",
    "        \n",
    "                    WRIST0 = [handLms0.landmark[0].x, handLms0.landmark[0].y, handLms0.landmark[0].z] \n",
    "                    THUMB0 = [handLms0.landmark[4].x, handLms0.landmark[4].y, handLms0.landmark[4].z]\n",
    "                    d0 = distance(WRIST0[0],WRIST0[1], THUMB0[0], THUMB0[1])\n",
    "                \n",
    "                    WRIST1 = [handLms1.landmark[0].x, handLms1.landmark[0].y, handLms1.landmark[0].z] \n",
    "                    THUMB1 = [handLms1.landmark[4].x, handLms1.landmark[4].y, handLms1.landmark[4].z]\n",
    "                    d1 = distance(WRIST1[0],WRIST1[1], THUMB1[0], THUMB1[1])\n",
    "                    \n",
    "                    if d0>d1:\n",
    "                        LH_INDEX = indexes[0]\n",
    "                    else:\n",
    "                        LH_INDEX = indexes[1]\n",
    "    \n",
    "                elif len(indexes)>2:\n",
    "                    print(\"EXCEPTION #1: More than two %s hands found in the video.\\n\"%(hand))\n",
    "                    print(\"=\"*20)\n",
    "                    \n",
    "        \n",
    "        '''\n",
    "        If the hand is not detected, landmark remains empty {}.\n",
    "        '''\n",
    "        if LH_INDEX == -1:\n",
    "            return image, landmarks\n",
    "        \n",
    "        '''\n",
    "        Now that we know the index of the desired hand, just extract the landmarks that matter and return.\n",
    "        '''\n",
    "        handLms = self.results.multi_hand_landmarks[LH_INDEX]\n",
    "        \n",
    "        landmarks[\"WRIST\"] = [handLms.landmark[0].x, handLms.landmark[0].y, handLms.landmark[0].z] \n",
    "        landmarks[\"THUMB_TIP\"] = [handLms.landmark[4].x, handLms.landmark[4].y, handLms.landmark[4].z]\n",
    "        landmarks[\"INDEX_FINGER_TIP\"] = [handLms.landmark[8].x, handLms.landmark[8].y, handLms.landmark[8].z]\n",
    "        landmarks[\"MIDDLE_FINGER_TIP\"] = [handLms.landmark[12].x, handLms.landmark[12].y, handLms.landmark[12].z]\n",
    "        landmarks[\"RING_FINGER_TIP\"] = [handLms.landmark[16].x, handLms.landmark[16].y, handLms.landmark[16].z]\n",
    "        landmarks[\"PINKY_TIP\"] = [handLms.landmark[20].x, handLms.landmark[20].y, handLms.landmark[20].z]\n",
    "        landmarks[\"THUMB_CMC\"] = [handLms.landmark[1].x, handLms.landmark[1].y, handLms.landmark[1].z]\n",
    "\n",
    "        if draw:\n",
    "            self.mpDraw.draw_landmarks(image, handLms, self.mpHands.HAND_CONNECTIONS)\n",
    "                \n",
    "        return image, landmarks\n",
    "\n",
    "class Signal:\n",
    "    \n",
    "    NOT_FOUND = -1\n",
    "    INTERRUPTION_SPEED_THRESHOLD = 50 #degree per second\n",
    "    INTERRUPTION_MIN_DURATION = 0.20 #second\n",
    "    FREEZE_SPEED_THRESHOLD = 50 #degree per second\n",
    "    FREEZE_MIN_DURATION = 0.30 #second\n",
    "        \n",
    "    def __init__(self, raw, wrist_raw, num_frames, duration):\n",
    "        self.raw_signal = raw\n",
    "        self.wrist_raw = wrist_raw\n",
    "        self.raw_fft = fft(self.raw_signal)\n",
    "        self.NUM_FRAMES = num_frames\n",
    "        self.DURATION = duration\n",
    "        self.PER_FRAME_DURATION = self.DURATION/self.NUM_FRAMES\n",
    "        self.denoised_signal, self.wrist_denoised = self.interpolation_and_denoise()\n",
    "        \n",
    "        self.peaks_denoised = self.peak_detection(self.denoised_signal)\n",
    "        self.peaks_trimmed = np.asarray(self.peaks_denoised[1:-1]-self.peaks_denoised[1])\n",
    "        \n",
    "        self.trimmed_signal = np.asarray(self.denoised_signal[self.peaks_denoised[1]:(self.peaks_denoised[-2]+1)])\n",
    "        self.wrist_trimmed = self.wrist_denoised[self.peaks_denoised[1]:(self.peaks_denoised[-2]+1)]\n",
    "        \n",
    "        self.signals = {'r':self.raw_signal, 'd':self.denoised_signal, 't':self.trimmed_signal}\n",
    "        self.peaks = {'d':self.peaks_denoised, 't':self.peaks_trimmed}\n",
    "        self.periods_denoised = []\n",
    "        self.periods_trimmed = []\n",
    "        self.speed_denoised = []\n",
    "        self.speed_trimmed = []\n",
    "        self.acceleration_denoised = []\n",
    "        self.acceleration_trimmed = []\n",
    "        \n",
    "        for i in range(1,len(self.peaks_denoised)):\n",
    "            self.periods_denoised.append((self.peaks_denoised[i]-self.peaks_denoised[i-1])*self.PER_FRAME_DURATION)\n",
    "            \n",
    "        for i in range(1,len(self.peaks_trimmed)):\n",
    "            self.periods_trimmed.append((self.peaks_trimmed[i]-self.peaks_trimmed[i-1])*self.PER_FRAME_DURATION)\n",
    "        \n",
    "        for i in range(0,len(self.denoised_signal)-1):\n",
    "            self.speed_denoised.append(self.denoised_signal[i+1]-self.denoised_signal[i])\n",
    "            \n",
    "        self.speed_denoised = np.asarray(self.speed_denoised) #degree per frame\n",
    "        self.speed_denoised = self.speed_denoised/self.PER_FRAME_DURATION #degree per second\n",
    "        \n",
    "        for i in range(0,len(self.trimmed_signal)-1):\n",
    "            self.speed_trimmed.append(self.trimmed_signal[i+1]-self.trimmed_signal[i])\n",
    "            \n",
    "        self.speed_trimmed = np.asarray(self.speed_trimmed) #degree per frame\n",
    "        self.speed_trimmed = self.speed_trimmed/self.PER_FRAME_DURATION #degree per second\n",
    "        self.speeds = {'d':self.speed_denoised, 't':self.speed_trimmed}\n",
    "        \n",
    "        for i in range(0,len(self.speed_denoised)-1):\n",
    "            self.acceleration_denoised.append(self.speed_denoised[i+1]-self.speed_denoised[i])\n",
    "            \n",
    "        self.acceleration_denoised = np.asarray(self.acceleration_denoised) #degree per frame*second\n",
    "        self.acceleration_denoised = self.acceleration_denoised/self.PER_FRAME_DURATION #degree per second2\n",
    "        \n",
    "        for i in range(0,len(self.speed_trimmed)-1):\n",
    "            self.acceleration_trimmed.append(self.speed_trimmed[i+1]-self.speed_trimmed[i])\n",
    "            \n",
    "        self.acceleration_trimmed = np.asarray(self.acceleration_trimmed) #degree per frame*second\n",
    "        self.acceleration_trimmed = self.acceleration_trimmed/self.PER_FRAME_DURATION #degree per second2\n",
    "\n",
    "    def interpolation_and_denoise(self):\n",
    "        D = denoise(self.raw_signal)\n",
    "        \n",
    "        '''\n",
    "        Take the maximum length segment where angle is not -1 (valid angular distance -- visible hand)\n",
    "        '''\n",
    "        first_frame = self.NOT_FOUND\n",
    "        last_frame = self.NOT_FOUND\n",
    "\n",
    "        max_first_frame = -1\n",
    "        max_last_frame = -1\n",
    "        max_num_frames = 0\n",
    "\n",
    "\n",
    "        for i in range(0,len(D)):\n",
    "            if D[i]!=self.NOT_FOUND:\n",
    "                if first_frame==self.NOT_FOUND:\n",
    "                    first_frame = i\n",
    "                else:\n",
    "                    last_frame = i\n",
    "                    num_frames = last_frame - first_frame +1\n",
    "                    if num_frames>max_num_frames:\n",
    "                        max_num_frames = num_frames\n",
    "                        max_first_frame = first_frame\n",
    "                        max_last_frame = last_frame\n",
    "            else:\n",
    "                first_frame = self.NOT_FOUND\n",
    "                last_frame = self.NOT_FOUND\n",
    "\n",
    "        D = D[max_first_frame:max_last_frame+1]\n",
    "        W = self.wrist_raw[max_first_frame:max_last_frame+1]\n",
    "        return D, W\n",
    "    \n",
    "    def peak_detection(self, D):\n",
    "        \n",
    "        '''\n",
    "        Run peak detection, the parameters could be further improved/optimized\n",
    "        '''\n",
    "        X = np.arange(0,len(D))\n",
    "        MIN_PERIOD = 0.15 #in seconds\n",
    "        d_min = (int)(MIN_PERIOD/self.PER_FRAME_DURATION)\n",
    "        peaks = custom_peaks(D, distance=d_min)\n",
    "    \n",
    "        '''\n",
    "        Cancel peaks where there is no minima between this peak and the previous peak\n",
    "        '''\n",
    "        n_peaks = len(peaks)\n",
    "        \n",
    "        bottoms = custom_bottoms(D, d_min)\n",
    "        n_bottoms = len(bottoms)\n",
    "        middle_bottoms = D[bottoms[(int)(np.floor((n_bottoms-1)/4)):(int)(np.floor(3*(n_bottoms-1)/4))]]\n",
    "        BOTTOM_MAX_HEIGHT = 10\n",
    "        print(\"Number of frames for a peak: %d\"%(d_min))\n",
    "        print(\"Bottom max height: %.3f\"%(BOTTOM_MAX_HEIGHT))\n",
    "    \n",
    "        peaks_denoised = [peaks[0]]\n",
    "        for i in range(0,len(peaks)-1):\n",
    "\n",
    "            min_val = 180.0\n",
    "            for j in range(peaks[i],peaks[i+1]):\n",
    "                if D[j]<min_val:\n",
    "                    min_val = D[j]\n",
    "\n",
    "            if min_val<BOTTOM_MAX_HEIGHT:\n",
    "                peaks_denoised.append(peaks[i+1])\n",
    "            \n",
    "        return peaks_denoised\n",
    "        \n",
    "    def aperiodicity(self,signal_version):\n",
    "        '''\n",
    "        signal_version = ['r','d','t']\n",
    "        '''\n",
    "        X = fft(self.signals[signal_version.lower()])\n",
    "        power_spectrum = np.square(np.abs(X))\n",
    "        power_spectrum = power_spectrum/power_spectrum.sum()\n",
    "        return entropy(power_spectrum)\n",
    "        \n",
    "    def interruption_count(self,signal_version):\n",
    "        '''\n",
    "        signal version = ['d','t']\n",
    "        '''\n",
    "        n = 0\n",
    "        S = np.abs(self.speeds[signal_version.lower()])\n",
    "        t = 0\n",
    "        for i in range(0,len(S)):\n",
    "            if S[i]<=self.INTERRUPTION_SPEED_THRESHOLD:\n",
    "                t +=1\n",
    "            else:\n",
    "                if (t*self.PER_FRAME_DURATION)>=self.INTERRUPTION_MIN_DURATION:\n",
    "                    n +=1\n",
    "                t = 0\n",
    "        return n\n",
    "    \n",
    "    def freeze_count(self,signal_version):\n",
    "        '''\n",
    "        signal version = ['d','t']\n",
    "        '''\n",
    "        n = 0\n",
    "        S = np.abs(self.speeds[signal_version.lower()])\n",
    "        t = 0\n",
    "        for i in range(0,len(S)):\n",
    "            if S[i]<=self.FREEZE_SPEED_THRESHOLD:\n",
    "                t +=1\n",
    "            else:\n",
    "                if (t*self.PER_FRAME_DURATION)>=self.FREEZE_MIN_DURATION:\n",
    "                    n +=1\n",
    "                t = 0\n",
    "        return n\n",
    "    \n",
    "    def max_freeze_duration(self,signal_version):\n",
    "        '''\n",
    "        signal version = ['d','t']\n",
    "        '''\n",
    "        S = np.abs(self.speeds[signal_version.lower()])\n",
    "        t = 0\n",
    "        t_max = 0\n",
    "        for i in range(0,len(S)):\n",
    "            if S[i]<=self.FREEZE_SPEED_THRESHOLD:\n",
    "                t +=1\n",
    "            else:\n",
    "                if t>t_max:\n",
    "                    t_max = t\n",
    "                t = 0\n",
    "        return (t_max*self.PER_FRAME_DURATION)\n",
    "    \n",
    "    def amplitude_decrement(self,signal_version):\n",
    "        '''\n",
    "        signal version = ['d','t']\n",
    "        '''\n",
    "        D = self.signals[signal_version]\n",
    "        t = self.peaks[signal_version]\n",
    "        A = D[t]\n",
    "        n = len(A)\n",
    "        assert (n>=2),\"Not enough peaks to analyze\"\n",
    "        n1 = round(n/2)\n",
    "        feats = linear_regression_fit(t, -A)\n",
    "        feats['end_to_mean'] = np.mean(A) - A[-1]\n",
    "        feats['fit_min_degree'] = degree_for_good_fit(t,A)\n",
    "        feats['last_to_first_half'] = np.mean(A[:(n1+1)]) - np.mean(A[(n1+1):])\n",
    "            \n",
    "        return feats\n",
    "    \n",
    "    def amplitude_stats(self, signal_version):\n",
    "        '''\n",
    "        signal version = ['d','t']\n",
    "        '''\n",
    "        D = self.signals[signal_version]\n",
    "        t = self.peaks[signal_version]\n",
    "        A = D[t]\n",
    "        texts = {\"d\":\"denoised\", \"t\":\"trimmed\"}\n",
    "        feats = {}\n",
    "        amp_stats = get_stats(A)\n",
    "        for k in amp_stats.keys():\n",
    "            feats[\"amplitude_\"+k+\"_\"+texts[signal_version]] = amp_stats[k]\n",
    "            \n",
    "        feats['amplitude_entropy_'+texts[signal_version]] = angular_amplitude_entropy(A)\n",
    "        \n",
    "        return feats\n",
    "        \n",
    "    \n",
    "    def wrist_movements(self):\n",
    "        W = self.wrist_trimmed\n",
    "        n = len(W)\n",
    "        movements_x = []\n",
    "        movements_y = []\n",
    "        movements_d = []\n",
    "        for i in range(1,n):\n",
    "            (x1,y1) = W[i]\n",
    "            (x0,y0) = W[i-1]\n",
    "            \n",
    "            if x1==self.NOT_FOUND or x0==self.NOT_FOUND:\n",
    "                movements_x.append(0)\n",
    "                movements_y.append(0)\n",
    "                movements_d.append(0)\n",
    "            else:\n",
    "                movements_x.append((x1-x0)/self.PER_FRAME_DURATION)\n",
    "                movements_y.append((y1-y0)/self.PER_FRAME_DURATION)\n",
    "                movements_d.append((distance(x0,y0,x1,y1))/self.PER_FRAME_DURATION)\n",
    "                \n",
    "        feats = {}\n",
    "        feats_x = get_stats(np.abs(movements_x))\n",
    "        for k in feats_x.keys():\n",
    "            feats['wrist_mvmnt_x_'+k] = feats_x[k]\n",
    "            \n",
    "        feats_y = get_stats(np.abs(movements_y))\n",
    "        for k in feats_y.keys():\n",
    "            feats['wrist_mvmnt_y_'+k] = feats_y[k]\n",
    "            \n",
    "        feats_d = get_stats(np.abs(movements_d))\n",
    "        for k in feats_d.keys():\n",
    "            feats['wrist_mvmnt_dist_'+k] = feats_d[k]\n",
    "        \n",
    "        return feats\n",
    "\n",
    "#Feature extractor from MediaPipe Key Points\n",
    "def get_final_features(data):\n",
    "    '''\n",
    "    data: \n",
    "    {\n",
    "        'D_raw':np.array, \n",
    "        'W_raw': list of normalized wrist coordinates (x,y),\n",
    "        'num_frames':int,\n",
    "        'duration':float\n",
    "    }\n",
    "    '''\n",
    "    \n",
    "    signal = Signal(data['D_raw'], data['W_raw'], data['num_frames'], data['duration'])\n",
    "    \n",
    "    '''\n",
    "    Features related to wrist movement (horizontal, vertical, and in cartesian coord)\n",
    "    '''\n",
    "    features = signal.wrist_movements()\n",
    "    \n",
    "    '''\n",
    "    Features related to rhythm\n",
    "    '''\n",
    "    features['aperiodicity_denoised'] = signal.aperiodicity('d')\n",
    "    features['aperiodicity_trimmed'] = signal.aperiodicity('t')\n",
    "    features['periodEntropy_denoised'] = period_entropy(signal.periods_denoised)\n",
    "    features['periodEntropy_trimmed'] = period_entropy(signal.periods_trimmed)\n",
    "    features['periodVarianceNorm_denoised'] = np.var(signal.periods_denoised)/np.max(signal.periods_denoised)\n",
    "    features['periodVarianceNorm_trimmed'] = np.var(signal.periods_trimmed)/np.max(signal.periods_trimmed)\n",
    "    features['numInterruptions_denoised'] = signal.interruption_count('d')\n",
    "    features['numInterruptions_trimmed'] = signal.interruption_count('t')\n",
    "    features['numFreeze_denoised'] = signal.freeze_count('d')\n",
    "    features['numFreeze_trimmed'] = signal.freeze_count('t')\n",
    "    features['maxFreezeDuration_denoised'] = signal.max_freeze_duration('d')\n",
    "    features['maxFreezeDuration_trimmed'] = signal.max_freeze_duration('t')\n",
    "    \n",
    "    '''\n",
    "    Statistics of Period, Frequency, and Amplitude\n",
    "    '''\n",
    "    period_stats_denoised = get_stats(signal.periods_denoised)\n",
    "    for k in period_stats_denoised.keys():\n",
    "        features['period_'+k+\"_denoised\"] = period_stats_denoised[k]\n",
    "         \n",
    "    period_stats_trimmed = get_stats(signal.periods_trimmed)\n",
    "    for k in period_stats_trimmed.keys():\n",
    "        features['period_'+k+\"_trimmed\"] = period_stats_trimmed[k]\n",
    "        \n",
    "    features['period_entropy_denoised'] = period_entropy(signal.periods_denoised)\n",
    "    features['period_entropy_trimmed'] = period_entropy(signal.periods_trimmed)\n",
    "    \n",
    "    frequency_stats_denoised = get_stats(1.0/np.asarray(signal.periods_denoised))\n",
    "    for k in frequency_stats_denoised.keys():\n",
    "        features['frequency_'+k+\"_denoised\"] = frequency_stats_denoised[k]\n",
    "        \n",
    "    frequency_stats_trimmed = get_stats(1.0/np.asarray(signal.periods_trimmed))\n",
    "    for k in frequency_stats_trimmed.keys():\n",
    "        features['frequency_'+k+\"_trimmed\"] = frequency_stats_trimmed[k]\n",
    "        \n",
    "    frequency_fit_denoised = linear_regression_fit(np.arange(0,len(signal.periods_denoised)), 1.0/np.asarray(signal.periods_denoised))\n",
    "    for k in frequency_fit_denoised.keys():\n",
    "        features['frequency_lr_'+k+'_denoised'] = frequency_fit_denoised[k]\n",
    "        \n",
    "    frequency_fit_trimmed = linear_regression_fit(np.arange(0,len(signal.periods_trimmed)), 1.0/np.asarray(signal.periods_trimmed))\n",
    "    for k in frequency_fit_trimmed.keys():\n",
    "        features['frequency_lr_'+k+'_trimmed'] = frequency_fit_trimmed[k]\n",
    "        \n",
    "    features['frequency_fit_min_degree_denoised'] = degree_for_good_fit(np.arange(0,len(signal.periods_denoised)), 1.0/np.asarray(signal.periods_denoised))\n",
    "    features['frequency_fit_min_degree_trimmed'] = degree_for_good_fit(np.arange(0,len(signal.periods_trimmed)), 1.0/np.asarray(signal.periods_trimmed))\n",
    "    \n",
    "    amp_stats = signal.amplitude_stats('d')\n",
    "    for k in amp_stats:\n",
    "        features[k] = amp_stats[k]\n",
    "        \n",
    "    amp_stats = signal.amplitude_stats('t')\n",
    "    for k in amp_stats:\n",
    "        features[k] = amp_stats[k]\n",
    "    '''\n",
    "    Amplitude decrement\n",
    "    '''\n",
    "    amp_dec_denoised = signal.amplitude_decrement('d')\n",
    "    for k in amp_dec_denoised.keys():\n",
    "        features['amplitude_decrement_'+k+'_denoised'] = amp_dec_denoised[k]\n",
    "        \n",
    "    amp_dec_trimmed = signal.amplitude_decrement('t')\n",
    "    for k in amp_dec_trimmed.keys():\n",
    "        features['amplitude_decrement_'+k+'_trimmed'] = amp_dec_trimmed[k]\n",
    "        \n",
    "    '''\n",
    "    Signal\n",
    "    '''\n",
    "    features['num_peaks_trimmed'] = len(signal.peaks_trimmed)\n",
    "    features['num_peaks_denoised'] = len(signal.peaks_denoised)\n",
    "    features['num_interruptions_norm_denoised'] = features['numInterruptions_denoised']/features['num_peaks_denoised']\n",
    "    features['num_freeze_norm_denoised'] = features['numFreeze_denoised']/features['num_peaks_denoised']\n",
    "    features['num_interruptions_norm_trimmed'] = features['numInterruptions_trimmed']/features['num_peaks_trimmed']\n",
    "    features['num_freeze_norm_trimmed'] = features['numFreeze_trimmed']/features['num_peaks_trimmed']\n",
    "    \n",
    "    speed_stats_denoised = get_stats(np.abs(signal.speed_denoised))\n",
    "    for k in speed_stats_denoised.keys():\n",
    "        features['speed_'+k+\"_denoised\"] = speed_stats_denoised[k]\n",
    "        \n",
    "    speed_stats_trimmed = get_stats(np.abs(signal.speed_trimmed))\n",
    "    for k in speed_stats_trimmed.keys():\n",
    "        features['speed_'+k+\"_trimmed\"] = speed_stats_trimmed[k]\n",
    "        \n",
    "    acceleration_stats_denoised = get_stats(np.abs(signal.acceleration_denoised))\n",
    "    for k in acceleration_stats_denoised.keys():\n",
    "        features['acceleration_'+k+\"_denoised\"] = acceleration_stats_denoised[k]\n",
    "        \n",
    "    acceleration_stats_trimmed = get_stats(np.abs(signal.acceleration_trimmed))\n",
    "    for k in acceleration_stats_trimmed.keys():\n",
    "        features['acceleration_'+k+\"_trimmed\"] = acceleration_stats_trimmed[k]\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "#Extract features from a given file and specified target hand\n",
    "def extract_features(filename, output_path, hand, labels=(0,\"\")):\n",
    "    '''\n",
    "    For the filename, create a folder and save the plots, MP annotations, and mid-level features there.\n",
    "    return features as a dictionary\n",
    "\n",
    "    hand: left, right\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    <intermediate-feature-file>  \n",
    "    <output-video-with-mp-annotation>\n",
    "    '''\n",
    "\n",
    "    hand = hand.lower()\n",
    "    FEATURE_DIR = output_path\n",
    "    annotations = {}\n",
    "    (annotations['rating'], annotations['diagnosis']) = labels\n",
    "    features = {}\n",
    "\n",
    "    base_file = os.path.basename(filename)\n",
    "    base_file = base_file[0:base_file.find(\".mp4\")]\n",
    "\n",
    "    full_dir_path = os.path.join(FEATURE_DIR,base_file)\n",
    "    if not os.path.exists(full_dir_path):\n",
    "        os.mkdir(full_dir_path)\n",
    "\n",
    "    full_dir_path = os.path.join(full_dir_path,hand.upper())\n",
    "\n",
    "    if os.path.exists(full_dir_path):\n",
    "        with open(os.path.join(full_dir_path,\"intermediate_features.pkl\"), 'rb') as handle:\n",
    "            data = pickle.load(handle)\n",
    "            features = get_final_features(data)\n",
    "\n",
    "        return features\n",
    "\n",
    "    '''\n",
    "    Process a new file\n",
    "    '''\n",
    "    os.mkdir(full_dir_path)\n",
    "    annotation_image_path = os.path.join(full_dir_path,\"MP Annotation Frames\")\n",
    "    annotation_json_path = os.path.join(full_dir_path,\"MP Annotation JSON\")\n",
    "    os.mkdir(annotation_image_path)\n",
    "    os.mkdir(annotation_json_path)\n",
    "\n",
    "    cap = cv.VideoCapture(filename)\n",
    "\n",
    "    tracker = HandTrackerCustomized()\n",
    "    cv.startWindowThread()\n",
    "\n",
    "    D = [] #Time-series of angular distance\n",
    "    W = [] #Time-seris of wrist coordinates (normalized): (W.x, W.y) -- requires all videos to be in the same size\n",
    "    NOT_FOUND = -1 #Constant\n",
    "    NUM_FRAMES = 0#nt the number of frames in the video\n",
    "\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        NUM_FRAMES +=1\n",
    "\n",
    "        width  = (int)(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "        height = (int)(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "        #print(width, height)\n",
    "\n",
    "        if NUM_FRAMES==1:\n",
    "            out = cv.VideoWriter(os.path.join(full_dir_path,\"finger_tapping_demo.mp4\"), cv.VideoWriter_fourcc(*'mp4v'), 15, (width, height))\n",
    "\n",
    "        #frame is updated by mediapipe (ref call)\n",
    "        visual, landmarks = tracker.handsFinder(frame, hand=hand, draw=True)\n",
    "\n",
    "        '''\n",
    "        Below is the data structure of landmarks returned:\n",
    "            landmarks[\"WRIST\"] = [x y z]\n",
    "            landmarks[\"THUMB_TIP\"] = [x y z]\n",
    "            landmarks[\"INDEX_FINGER_TIP\"] = [x y z]\n",
    "            landmarks[\"MIDDLE_FINGER_TIP\"] = [x y z]\n",
    "            landmarks[\"RING_FINGER_TIP\"] = [x y z]\n",
    "            landmarks[\"PINKY_TIP\"] = [x y z]\n",
    "        '''\n",
    "\n",
    "        if \"WRIST\" in landmarks.keys():\n",
    "            wrist_x = (int)(landmarks[\"WRIST\"][0]*width)\n",
    "            wrist_y = (int)(landmarks[\"WRIST\"][1]*height)\n",
    "\n",
    "            thumb_x = (int)(landmarks[\"THUMB_TIP\"][0]*width)\n",
    "            thumb_y = (int)(landmarks[\"THUMB_TIP\"][1]*height)\n",
    "\n",
    "            index_x = (int)(landmarks[\"INDEX_FINGER_TIP\"][0]*width)\n",
    "            index_y = (int)(landmarks[\"INDEX_FINGER_TIP\"][1]*height)\n",
    "\n",
    "            cv.line(frame, (wrist_x, wrist_y), (thumb_x, thumb_y), (255,0,0), 2)\n",
    "            cv.line(frame, (wrist_x, wrist_y), (index_x, index_y), (0,0,255), 2)\n",
    "\n",
    "            Vector_WT = ((thumb_x-wrist_x),(thumb_y-wrist_y))\n",
    "            Vector_WI = ((index_x-wrist_x),(index_y-wrist_y))\n",
    "            dot = Vector_WT[0]*Vector_WI[0] + Vector_WT[1]*Vector_WI[1]\n",
    "            cosx = dot/(math.sqrt((Vector_WT[0]**2)+(Vector_WT[1]**2))*math.sqrt((Vector_WI[0]**2)+(Vector_WI[1]**2)))\n",
    "            cosx = np.minimum(cosx,1.0)\n",
    "            angle = (math.acos(cosx)*180)/math.pi\n",
    "\n",
    "            D.append(angle)\n",
    "\n",
    "            thumb_cmc_x = (int)(landmarks[\"THUMB_CMC\"][0]*width)\n",
    "            thumb_cmc_y = (int)(landmarks[\"THUMB_CMC\"][1]*height)\n",
    "\n",
    "            w_norm = distance(wrist_x, wrist_y, thumb_cmc_x, thumb_cmc_y)\n",
    "            W.append((wrist_x/w_norm, wrist_y/w_norm))\n",
    "\n",
    "        else:\n",
    "            D.append(NOT_FOUND)\n",
    "            W.append((NOT_FOUND, NOT_FOUND))\n",
    "\n",
    "\n",
    "        cv.imshow(filename, frame)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "        k = cv.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "    cv.waitKey(1)\n",
    "    out.release()\n",
    "\n",
    "    '''\n",
    "    Extract intermediate representations for the features\n",
    "    '''\n",
    "\n",
    "    INT_FEATS = {}\n",
    "    INT_FEATS[\"D_raw\"] = np.asarray(D)\n",
    "    INT_FEATS[\"W_raw\"] = W\n",
    "\n",
    "    #Video Processing Done\n",
    "    DURATION = get_length(filename)\n",
    "\n",
    "    PER_FRAME_DURATION = DURATION/NUM_FRAMES\n",
    "\n",
    "    INT_FEATS[\"duration\"] = DURATION\n",
    "    INT_FEATS[\"num_frames\"] = NUM_FRAMES\n",
    "\n",
    "    with open(os.path.join(full_dir_path,\"intermediate_features.pkl\"), 'wb') as handle:\n",
    "        pickle.dump(INT_FEATS, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(os.path.join(full_dir_path,\"intermediate_features.pkl\"), 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "        features = get_final_features(data)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c710557d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames for a peak: 3\n",
      "Bottom max height: 10.000\n"
     ]
    }
   ],
   "source": [
    "filename=\"finger_tapping_demo.mp4\"\n",
    "output=\"D:\\Codes\\Python programming\\Finger-Tappping\"\n",
    "features=extract_features(filename,output,\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1d64ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wrist_mvmnt_x_median': 7.009714918451104,\n",
       " 'wrist_mvmnt_x_quartile_range': array(11.36479316),\n",
       " 'wrist_mvmnt_x_mean': 9.222492067072041,\n",
       " 'wrist_mvmnt_x_min': 0.0,\n",
       " 'wrist_mvmnt_x_max': 53.06391078387147,\n",
       " 'wrist_mvmnt_x_stdev': 10.256312742947959,\n",
       " 'wrist_mvmnt_y_median': 10.541024933838905,\n",
       " 'wrist_mvmnt_y_quartile_range': array(17.74302211),\n",
       " 'wrist_mvmnt_y_mean': 14.030837280452177,\n",
       " 'wrist_mvmnt_y_min': 0.0,\n",
       " 'wrist_mvmnt_y_max': 75.7175278369544,\n",
       " 'wrist_mvmnt_y_stdev': 15.701422909054017,\n",
       " 'wrist_mvmnt_dist_median': 12.285382139226606,\n",
       " 'wrist_mvmnt_dist_quartile_range': array(20.35237404),\n",
       " 'wrist_mvmnt_dist_mean': 16.916921374540784,\n",
       " 'wrist_mvmnt_dist_min': 0.0,\n",
       " 'wrist_mvmnt_dist_max': 92.46038421626116,\n",
       " 'wrist_mvmnt_dist_stdev': 18.640363686780944,\n",
       " 'aperiodicity_denoised': 1.1433355760375534,\n",
       " 'aperiodicity_trimmed': 1.1030333233246576,\n",
       " 'periodEntropy_denoised': 0.5536994379236184,\n",
       " 'periodEntropy_trimmed': 0.5384879716476932,\n",
       " 'periodVarianceNorm_denoised': 0.03819852941176471,\n",
       " 'periodVarianceNorm_trimmed': 0.04188475390156062,\n",
       " 'numInterruptions_denoised': 2,\n",
       " 'numInterruptions_trimmed': 2,\n",
       " 'numFreeze_denoised': 0,\n",
       " 'numFreeze_trimmed': 0,\n",
       " 'maxFreezeDuration_denoised': 0.24,\n",
       " 'maxFreezeDuration_trimmed': 0.24,\n",
       " 'period_median_denoised': 0.22,\n",
       " 'period_quartile_range_denoised': array(0.14826022),\n",
       " 'period_mean_denoised': 0.28500000000000003,\n",
       " 'period_min_denoised': 0.12,\n",
       " 'period_max_denoised': 0.68,\n",
       " 'period_stdev_denoised': 0.161167614612862,\n",
       " 'period_median_trimmed': 0.22,\n",
       " 'period_quartile_range_trimmed': array(0.14826022),\n",
       " 'period_mean_trimmed': 0.2942857142857143,\n",
       " 'period_min_trimmed': 0.12,\n",
       " 'period_max_trimmed': 0.68,\n",
       " 'period_stdev_trimmed': 0.16876502200711269,\n",
       " 'period_entropy_denoised': 0.5536994379236184,\n",
       " 'period_entropy_trimmed': 0.5384879716476932,\n",
       " 'frequency_median_denoised': 4.583333333333334,\n",
       " 'frequency_quartile_range_denoised': array(2.57396218),\n",
       " 'frequency_mean_denoised': 4.5890595821662,\n",
       " 'frequency_min_denoised': 1.4705882352941175,\n",
       " 'frequency_max_denoised': 8.333333333333334,\n",
       " 'frequency_stdev_denoised': 2.1388230302153493,\n",
       " 'frequency_median_trimmed': 4.583333333333334,\n",
       " 'frequency_quartile_range_trimmed': array(2.57396218),\n",
       " 'frequency_mean_trimmed': 4.543108910230759,\n",
       " 'frequency_min_trimmed': 1.4705882352941175,\n",
       " 'frequency_max_trimmed': 8.333333333333334,\n",
       " 'frequency_stdev_trimmed': 2.225969561275424,\n",
       " 'frequency_lr_fitness_r2_denoised': 0.12962144308220358,\n",
       " 'frequency_lr_slope_denoised': -0.16704512687427914,\n",
       " 'frequency_lr_fitness_r2_trimmed': 0.08537438731711833,\n",
       " 'frequency_lr_slope_trimmed': -0.16134530735371067,\n",
       " 'frequency_fit_min_degree_denoised': 10,\n",
       " 'frequency_fit_min_degree_trimmed': 9,\n",
       " 'amplitude_median_denoised': 12.034078487557291,\n",
       " 'amplitude_quartile_range_denoised': array(4.60870977),\n",
       " 'amplitude_mean_denoised': 12.906877208710286,\n",
       " 'amplitude_min_denoised': 8.925741562439033,\n",
       " 'amplitude_max_denoised': 20.36000039447812,\n",
       " 'amplitude_stdev_denoised': 3.3417747823631334,\n",
       " 'amplitude_entropy_denoised': 0.37887093905096236,\n",
       " 'amplitude_median_trimmed': 12.214085494020472,\n",
       " 'amplitude_quartile_range_trimmed': array(4.65933436),\n",
       " 'amplitude_mean_trimmed': 13.173106745915858,\n",
       " 'amplitude_min_trimmed': 8.925741562439033,\n",
       " 'amplitude_max_trimmed': 20.36000039447812,\n",
       " 'amplitude_stdev_trimmed': 3.4475443110536466,\n",
       " 'amplitude_entropy_trimmed': 0.38009376671593426,\n",
       " 'amplitude_decrement_fitness_r2_denoised': 0.0009388977542691412,\n",
       " 'amplitude_decrement_slope_denoised': -0.00298804413303178,\n",
       " 'amplitude_decrement_end_to_mean_denoised': 0.8727987211529946,\n",
       " 'amplitude_decrement_fit_min_degree_denoised': 10,\n",
       " 'amplitude_decrement_last_to_first_half_denoised': 0.38030654502912675,\n",
       " 'amplitude_decrement_fitness_r2_trimmed': 0.00032497460742730855,\n",
       " 'amplitude_decrement_slope_trimmed': 0.002088535794361123,\n",
       " 'amplitude_decrement_end_to_mean_trimmed': 0.9590212518953862,\n",
       " 'amplitude_decrement_fit_min_degree_trimmed': 10,\n",
       " 'amplitude_decrement_last_to_first_half_trimmed': -0.31561476513073394,\n",
       " 'num_peaks_trimmed': 15,\n",
       " 'num_peaks_denoised': 17,\n",
       " 'num_interruptions_norm_denoised': 0.11764705882352941,\n",
       " 'num_freeze_norm_denoised': 0.0,\n",
       " 'num_interruptions_norm_trimmed': 0.13333333333333333,\n",
       " 'num_freeze_norm_trimmed': 0.0,\n",
       " 'speed_median_denoised': 49.9571985847725,\n",
       " 'speed_quartile_range_denoised': array(41.02781549),\n",
       " 'speed_mean_denoised': 65.93193475298773,\n",
       " 'speed_min_denoised': 0.024684655218276674,\n",
       " 'speed_max_denoised': 329.38744482185075,\n",
       " 'speed_stdev_denoised': 59.70226316690556,\n",
       " 'speed_median_trimmed': 48.52075455050746,\n",
       " 'speed_quartile_range_trimmed': array(39.14027487),\n",
       " 'speed_mean_trimmed': 66.69836758563102,\n",
       " 'speed_min_trimmed': 0.024684655218276674,\n",
       " 'speed_max_trimmed': 329.38744482185075,\n",
       " 'speed_stdev_trimmed': 61.992190205188464,\n",
       " 'acceleration_median_denoised': 1751.4028306039963,\n",
       " 'acceleration_quartile_range_denoised': array(2046.40304347),\n",
       " 'acceleration_mean_denoised': 2353.9312600758212,\n",
       " 'acceleration_min_denoised': 24.194200062087567,\n",
       " 'acceleration_max_denoised': 11379.453733761238,\n",
       " 'acceleration_stdev_denoised': 2157.99220208539,\n",
       " 'acceleration_median_trimmed': 1768.9887544914388,\n",
       " 'acceleration_quartile_range_trimmed': array(2034.31218202),\n",
       " 'acceleration_mean_trimmed': 2394.8156086478875,\n",
       " 'acceleration_min_trimmed': 24.194200062087567,\n",
       " 'acceleration_max_trimmed': 11379.453733761238,\n",
       " 'acceleration_stdev_trimmed': 2180.329415276617}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d3aa1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ab5599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(features,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a8ed150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wrist_mvmnt_x_median</th>\n",
       "      <th>wrist_mvmnt_x_quartile_range</th>\n",
       "      <th>wrist_mvmnt_x_mean</th>\n",
       "      <th>wrist_mvmnt_x_min</th>\n",
       "      <th>wrist_mvmnt_x_max</th>\n",
       "      <th>wrist_mvmnt_x_stdev</th>\n",
       "      <th>wrist_mvmnt_y_median</th>\n",
       "      <th>wrist_mvmnt_y_quartile_range</th>\n",
       "      <th>wrist_mvmnt_y_mean</th>\n",
       "      <th>wrist_mvmnt_y_min</th>\n",
       "      <th>...</th>\n",
       "      <th>acceleration_mean_denoised</th>\n",
       "      <th>acceleration_min_denoised</th>\n",
       "      <th>acceleration_max_denoised</th>\n",
       "      <th>acceleration_stdev_denoised</th>\n",
       "      <th>acceleration_median_trimmed</th>\n",
       "      <th>acceleration_quartile_range_trimmed</th>\n",
       "      <th>acceleration_mean_trimmed</th>\n",
       "      <th>acceleration_min_trimmed</th>\n",
       "      <th>acceleration_max_trimmed</th>\n",
       "      <th>acceleration_stdev_trimmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.009715</td>\n",
       "      <td>11.364793</td>\n",
       "      <td>9.222492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.063911</td>\n",
       "      <td>10.256313</td>\n",
       "      <td>10.541025</td>\n",
       "      <td>17.743022</td>\n",
       "      <td>14.030837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2353.93126</td>\n",
       "      <td>24.1942</td>\n",
       "      <td>11379.453734</td>\n",
       "      <td>2157.992202</td>\n",
       "      <td>1768.988754</td>\n",
       "      <td>2034.312182</td>\n",
       "      <td>2394.815609</td>\n",
       "      <td>24.1942</td>\n",
       "      <td>11379.453734</td>\n",
       "      <td>2180.329415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wrist_mvmnt_x_median  wrist_mvmnt_x_quartile_range  wrist_mvmnt_x_mean  \\\n",
       "0              7.009715                     11.364793            9.222492   \n",
       "\n",
       "   wrist_mvmnt_x_min  wrist_mvmnt_x_max  wrist_mvmnt_x_stdev  \\\n",
       "0                0.0          53.063911            10.256313   \n",
       "\n",
       "   wrist_mvmnt_y_median  wrist_mvmnt_y_quartile_range  wrist_mvmnt_y_mean  \\\n",
       "0             10.541025                     17.743022           14.030837   \n",
       "\n",
       "   wrist_mvmnt_y_min  ...  acceleration_mean_denoised  \\\n",
       "0                0.0  ...                  2353.93126   \n",
       "\n",
       "   acceleration_min_denoised  acceleration_max_denoised  \\\n",
       "0                    24.1942               11379.453734   \n",
       "\n",
       "   acceleration_stdev_denoised  acceleration_median_trimmed  \\\n",
       "0                  2157.992202                  1768.988754   \n",
       "\n",
       "   acceleration_quartile_range_trimmed  acceleration_mean_trimmed  \\\n",
       "0                          2034.312182                2394.815609   \n",
       "\n",
       "   acceleration_min_trimmed  acceleration_max_trimmed  \\\n",
       "0                   24.1942              11379.453734   \n",
       "\n",
       "   acceleration_stdev_trimmed  \n",
       "0                 2180.329415  \n",
       "\n",
       "[1 rows x 116 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c017adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
